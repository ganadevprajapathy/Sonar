{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PySPt9HTR8y_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import typing\n",
        "import imageio\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "# from tensorflow.keras.datasets import mnist\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import glob\n",
        "import PIL\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mY4hKhkZSCU-"
      },
      "outputs": [],
      "source": [
        "# Define the generator model\n",
        "def build_generator(noise_dim, img_shape):\n",
        "    inputs = layers.Input(shape=noise_dim, name=\"input\")\n",
        "\n",
        "    # Modified Dense layer with new output size\n",
        "    x = layers.Dense(25 * 128 * 256, use_bias=False)(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    # Reshape to match the new dense layer output\n",
        "    x = layers.Reshape((25, 128, 256))(x)\n",
        "    assert x.shape == (None, 25, 128, 256)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "    assert x.shape == (None, 25, 128, 128)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "    assert x.shape == (None, 50, 256, 64)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.UpSampling2D(size=(2, 2))(x)\n",
        "    x = layers.Conv2D(1, (5, 5), strides=(1, 1), padding='same', use_bias=False)(x)\n",
        "\n",
        "    # Add tanh activation\n",
        "    x = layers.Activation('tanh')(x)\n",
        "    assert x.shape == (None, img_shape[0], img_shape[1], 1)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt9MNonSSLMl"
      },
      "outputs": [],
      "source": [
        "# Define the discriminator model\n",
        "def build_discriminator(img_shape):\n",
        "    inputs = layers.Input(shape=img_shape, name=\"input\")\n",
        "\n",
        "    x = layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    x = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbf63lBzSNUt"
      },
      "outputs": [],
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r6iMAiAKSQIW"
      },
      "outputs": [],
      "source": [
        "def generator_loss(fake_output):\n",
        "    return tf.keras.losses.BinaryCrossentropy(from_logits=True)(tf.ones_like(fake_output), fake_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_S9RhdmSR1-"
      },
      "outputs": [],
      "source": [
        "class GAN(tf.keras.models.Model):\n",
        "    \"\"\"A Generative Adversarial Network (GAN) implementation.\n",
        "\n",
        "    This class inherits from `tf.keras.models.Model` and provides a\n",
        "    straightforward implementation of the GAN algorithm.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            discriminator: tf.keras.models.Model,\n",
        "            generator: tf.keras.models.Model,\n",
        "            noise_dim: int\n",
        "        ) -> None:\n",
        "        \"\"\"Initializes the GAN class.\n",
        "\n",
        "        Args:\n",
        "            discriminator (tf.keras.models.Model): A `tf.keras.model.Model` instance that acts\n",
        "                as the discriminator in the GAN algorithm.\n",
        "            generator (tf.keras.models.Model): A `tf.keras.model.Model` instance that acts as\n",
        "                the generator in the GAN algorithm.\n",
        "            noise_dim (int): The dimensionality of the noise vector that is\n",
        "                inputted to the generator.\n",
        "        \"\"\"\n",
        "        super(GAN, self).__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.noise_dim = noise_dim\n",
        "\n",
        "    def compile(\n",
        "            self,\n",
        "            discriminator_opt: tf.keras.optimizers.Optimizer,\n",
        "            generator_opt: tf.keras.optimizers.Optimizer,\n",
        "            discriminator_loss: typing.Callable,\n",
        "            generator_loss: typing.Callable,\n",
        "            **kwargs\n",
        "        ) -> None:\n",
        "        \"\"\"Configures the model for training.\n",
        "\n",
        "        Args:\n",
        "            discriminator_opt (tf.keras.optimizers.Optimizer): The optimizer for the discriminator.\n",
        "            generator_opt (tf.keras.optimizers.Optimizer): The optimizer for the generator.\n",
        "            discriminator_loss (typing.Callable): The loss function for the discriminator.\n",
        "            generator_loss (typing.Callable): The loss function for the generator.\n",
        "        \"\"\"\n",
        "        super(GAN, self).compile(**kwargs)\n",
        "        self.discriminator_opt = discriminator_opt\n",
        "        self.generator_opt = generator_opt\n",
        "        self.discriminator_loss = discriminator_loss\n",
        "        self.generator_loss = generator_loss\n",
        "\n",
        "    def train_step(self, real_images: tf.Tensor) -> typing.Dict[str, tf.Tensor]:\n",
        "        \"\"\"Executes one training step and returns the loss.\n",
        "\n",
        "        Args:\n",
        "            real_images (tf.Tensor): A batch of real images from the dataset.\n",
        "\n",
        "        Returns:\n",
        "            typing.Dict[str, tf.Tensor]: A dictionary of metric values and losses.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(real_images)[0]\n",
        "        # Generate random noise for the generator\n",
        "        noise = tf.random.normal([batch_size, self.noise_dim])\n",
        "\n",
        "        # Train the discriminator with both real images (label as 1) and fake images (label as 0)\n",
        "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "            # Generate fake images using the generator\n",
        "            generated_images = self.generator(noise, training=True)\n",
        "\n",
        "            # Get the discriminator's predictions for real and fake images\n",
        "            real_output = self.discriminator(real_images, training=True)\n",
        "            fake_output = self.discriminator(generated_images, training=True)\n",
        "\n",
        "            # Calculate generator and discriminator losses\n",
        "            gen_loss = self.generator_loss(fake_output)\n",
        "            disc_loss = self.discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        # Calculate gradients of generator and discriminator\n",
        "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
        "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
        "\n",
        "        # Apply gradients to generator and discriminator optimizer\n",
        "        self.generator_opt.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
        "        self.discriminator_opt.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(real_output, fake_output)\n",
        "\n",
        "        # Construct a dictionary of metric results and losses\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        results.update({\"d_loss\": disc_loss, \"g_loss\": gen_loss})\n",
        "\n",
        "        return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e2k9T3FkSVAt"
      },
      "outputs": [],
      "source": [
        "class ResultsCallback(tf.keras.callbacks.Callback):\n",
        "    \"\"\"A callback that saves generated images after each epoch.\"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            noise_dim: int,\n",
        "            results_path: str,\n",
        "            examples_to_generate: int=16,\n",
        "            grid_size: tuple=(4, 4),\n",
        "            spacing: int=5,\n",
        "            gif_size: tuple=(416, 416),\n",
        "            duration: float=0.1\n",
        "        ):\n",
        "        \"\"\" Initializes the ResultsCallback class.\n",
        "\n",
        "        Args:\n",
        "            noise_dim (int): The dimensionality of the noise vector that is inputted to the generator.\n",
        "            results_path (str): The path to the directory where the results will be saved.\n",
        "            examples_to_generate (int, optional): The number of images to generate and save. Defaults to 16.\n",
        "            grid_size (tuple, optional): The size of the grid to arrange the generated images. Defaults to (4, 4).\n",
        "            spacing (int, optional): The spacing between the generated images. Defaults to 5.\n",
        "            gif_size (tuple, optional): The size of the gif to be generated. Defaults to (416, 416).\n",
        "            duration (float, optional): The duration of each frame in the gif. Defaults to 0.1.\n",
        "        \"\"\"\n",
        "        super(ResultsCallback, self).__init__()\n",
        "        self.seed = tf.random.normal([examples_to_generate, noise_dim])\n",
        "        self.results = []\n",
        "        self.results_path = results_path + '/results'\n",
        "        self.grid_size = grid_size\n",
        "        self.spacing = spacing\n",
        "        self.gif_size = gif_size\n",
        "        self.duration = duration\n",
        "\n",
        "        # create the results directory if it doesn't exist\n",
        "        os.makedirs(self.results_path, exist_ok=True)\n",
        "\n",
        "    def save_pred(self, epoch: int, results: list) -> None:\n",
        "        \"\"\" Saves the generated images as a grid and as a gif.\n",
        "\n",
        "        Args:\n",
        "            epoch (int): The current epoch.\n",
        "            results (list): A list of generated images.\n",
        "        \"\"\"\n",
        "        # construct an image from generated images with spacing between them using numpy\n",
        "        w, h , c = results[0].shape\n",
        "        # construct grid with self.grid_size\n",
        "        grid = np.zeros((self.grid_size[0] * w + (self.grid_size[0] - 1) * self.spacing, self.grid_size[1] * h + (self.grid_size[1] - 1) * self.spacing, c), dtype=np.uint8)\n",
        "        for i in range(self.grid_size[0]):\n",
        "            for j in range(self.grid_size[1]):\n",
        "                grid[i * (w + self.spacing):i * (w + self.spacing) + w, j * (h + self.spacing):j * (h + self.spacing) + h] = results[i * self.grid_size[1] + j]\n",
        "\n",
        "        # save the image\n",
        "        cv2.imwrite(f'{self.results_path}/img_{epoch}.jpg', grid)\n",
        "\n",
        "        # save image to memory resized to gif size\n",
        "        self.results.append(cv2.resize(grid, self.gif_size, interpolation=cv2.INTER_AREA))\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs: dict=None) -> None:\n",
        "        \"\"\"Executes at the end of each epoch.\"\"\"\n",
        "        predictions = self.model.generator(self.seed, training=False)\n",
        "        predictions_uint8 = (predictions * 127.5 + 127.5).numpy().astype(np.uint8)\n",
        "        self.save_pred(epoch, predictions_uint8)\n",
        "\n",
        "    def on_train_end(self, logs=None) -> None:\n",
        "        \"\"\"Executes at the end of training.\"\"\"\n",
        "        # save the results as a gif with imageio\n",
        "\n",
        "        # Create a list of imageio image objects from the OpenCV images\n",
        "        imageio_images = [imageio.core.util.Image(image) for image in self.results]\n",
        "\n",
        "        # Write the imageio images to a GIF file\n",
        "        imageio.mimsave(self.results_path + \"/output.gif\", imageio_images, duration=self.duration)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLsA4aPiSZhe"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "# data_dir = r\"C:\\Users\\Ganadev Prajapathy\\Documents\\Sonar\\Model\\Data Preparation 2\\Labelled_Tiles\"\n",
        "# data_dir = '/content/drive/MyDrive/Colab Notebooks/Sonar/Data Preparation 2/Labelled_Tiles'\n",
        "model_path = '/home/republic/Documents/Ganadev/Outputs/GANs/Results5'\n",
        "# data_dir = '/content/drive/MyDrive/Colab Notebooks/Sonar/TrainingDataset/Labelled_Target'\n",
        "# For just labelled mines\n",
        "data_dir = '/home/republic/Documents/Ganadev/Datasets/Labelled_Mines'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxCdCoUpSdM-"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "img_height = 100\n",
        "img_width = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fs1hmSrSfFN",
        "outputId": "328f84bd-55ab-496b-d0e1-6fabe096ff3a"
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  color_mode=\"grayscale\",\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2RiXfgcShVF",
        "outputId": "596a3bd6-441c-463a-d137-7a2df673420b"
      },
      "outputs": [],
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  color_mode=\"grayscale\",\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzJPJ294SjjW",
        "outputId": "f6e46623-5173-4504-f700-b83bdbfe71c8"
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJWJimWQSle-"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation\n",
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpLnI2rTSo1e",
        "outputId": "020bf01f-64ba-4346-812c-47859d418437"
      },
      "outputs": [],
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "    print(image_batch.shape)\n",
        "    print(labels_batch.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTe1AKGRSqQ2"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GjWm_JdSsL9"
      },
      "outputs": [],
      "source": [
        "# Normalising\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "# print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APnz1GlnSu8U"
      },
      "outputs": [],
      "source": [
        "# Set the input shape and size for the generator and discriminator\n",
        "img_shape = (img_height, img_width, 1) # The shape of the input image, input to the discriminator\n",
        "noise_dim = 100 # The dimension of the noise vector, input to the generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB7fg7E-SxR1"
      },
      "outputs": [],
      "source": [
        "generator = build_generator(noise_dim, img_shape)\n",
        "discriminator = build_discriminator(img_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBETSihaSzpM"
      },
      "outputs": [],
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCwEpct5S2rk"
      },
      "outputs": [],
      "source": [
        "callback = ResultsCallback(noise_dim=noise_dim, results_path=model_path)\n",
        "tb_callback = TensorBoard(model_path + '/logs', update_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1rt9laaS40c"
      },
      "outputs": [],
      "source": [
        "gan = GAN(discriminator, generator, noise_dim)\n",
        "gan.compile(discriminator_optimizer, generator_optimizer, discriminator_loss, generator_loss, run_eagerly=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI_FjuONS6ic",
        "outputId": "1a9db47c-1bfb-4f56-810c-889e5846df72"
      },
      "outputs": [],
      "source": [
        "gan.fit(image_batch, epochs=7000, batch_size=batch_size, callbacks=[callback, tb_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhSlyEfwS80k"
      },
      "outputs": [],
      "source": [
        "file_path = glob.glob(model_path + '/results/img_999.jpg')[0]  # Assuming JPG images\n",
        "PIL.Image.open(file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQpxJmSZtM54"
      },
      "outputs": [],
      "source": [
        "# Assuming the generator model is stored in the variable 'generator'\n",
        "noise_dim = 100  # Noise dimension used during training\n",
        "\n",
        "# Generate a random noise vector\n",
        "noise = np.random.normal([1, noise_dim])\n",
        "\n",
        "# Generate new data using the generator\n",
        "generated_image = generator(noise, training=False)\n",
        "\n",
        "# Convert the generated image from tensor to numpy array\n",
        "generated_image_array = generated_image.numpy()[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
